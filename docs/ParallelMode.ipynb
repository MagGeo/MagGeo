{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MagGeo - Parallel Mode {.unnumbered}\n",
    "\n",
    "**Authors** | Fernando Benitez-Paez, UrÅ¡ka DemÅ¡ar, Jed Long, Ciaran Beggan\n",
    "\n",
    "**Contact**  | [Fernando.Benitez@st-andrews.ac.uk](mailto:Fernando.Benitez@st-andrews.ac.uk), [ud2@st-andrews.ac.uk](mailto:ud2@st-andrews.ac.uk), [jed.long@uwo.ca](mailto:jed.long@uwo.ca), [ciar@bgs.ac.uk](mailto:Fernando.Benitez@st-andrews.ac.uk)\n",
    "\n",
    "**Keywords** | Bird migration, data fusion, Earthâ€™s magnetic field, Swarm, GPS tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This Jupyter Notebook will guide you through the required steps to annotate your GPS tracking data with the earth's magnetic field data from Swarm (European Space Agency). This version is called Parallel Mode to take advantage of parallelized computing to process big datasets.\n",
    "\n",
    "To execute the code, you can go through each cell (pressing <code>Crtl+Enter</code>), you will also find inner comments `##` to describe each particular step. If you are not familiar with Jupyter Notebook, you migth want to take some time to learn how to use it first, for example take a look at the <code>notebook-basics.ipynb</code> Notebook inside MagGeo.\n",
    "\n",
    "**For parallel processing, there are some considerations to make:**\n",
    "\n",
    "1. Linux and Windows environments have some differences. In windows we need to separate the functions and store them separately, then import them into a `main` function. \n",
    "3. Defining what part of the process is <strong>CPU bound</strong> and what part is <strong>I/O bound</strong>: Identify what parts of the program are I/O bound (writing or reading from the disk or network) and what part par CPU bound ( Processing capacity). To take advantage of our CPU capacity we need to identify the process where the CPU is actually doing the main Tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data requirements\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "  <strong>ðŸ”Ž Your trajectory must be in a csv format:</strong>\n",
    "\n",
    "There are three columns that  must be included in your GPS trajectory. Make sure your GPS trajectory includes  **Latitude** , **Longitude** and **timestamp**. We suggest that the Timestamp column follow the day/month/year Hour:Minute (**dd/mm/yyyy HH:MM:SS**) format, Latitude and Longitude should be in decimal degrees (WGS84). Optionally an altitude column can be used providing altitude (the altitude must be in **km**). Other Columns will be ignored. Here it is an example of how your GPS track should look:\n",
    "\n",
    "<img src=\"./images/TableExample.png\">\n",
    "\n",
    "For this example we are reading the <strong>BirdGPSTrajectory.csv</strong> file. If you want to run the method using your own csv file, make sure you store your the file in the <code>./data</code> folder. For more information about the dataset we used in this example go to the Main Notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the requeried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:42:36.049156Z",
     "start_time": "2021-02-16T17:42:30.346278Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from viresclient import set_token\n",
    "sys.path.append(\"..\")\n",
    "import utilities\n",
    "from utilities.MagGeoFunctions import getGPSData\n",
    "from utilities.MagGeoFunctions import Get_Swarm_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add your VirES web client Token\n",
    "\n",
    "The **VirES client API**, requires a token. Before start you need to get your own VirES token. You can visit https://vires.services/ to get yours, and then add it into the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:42:46.799356Z",
     "start_time": "2021-02-16T17:42:36.762546Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_token(\"https://vires.services/ows\", set_default=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the GPS track\n",
    "\n",
    "The following steps will load the GPS track from a csv file, and set some requirements before download the data from Swarm.\n",
    "Importing the GPS track. You can note that there is a folder to store the CSV file. Using `os.getcwd()` you can validate where the file is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=os.path.dirname(os.getcwd())\n",
    "temp_results_dir = os.path.join(base_dir, \"temp_data\")\n",
    "results_dir = os.path.join(base_dir, \"results\")\n",
    "data_dir = os.path.join(base_dir, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the csv file of your trajectory is stored in the Data folder.\n",
    "#Enter the name of your GPS track csv file including the extension .csv  and press Enter (e.g. BirdGPSTrajectory.csv)\n",
    "# Make sure you have a column that integrates date and time, before include in MagGeo.\n",
    "#If your csv track file does not have any altitude attribute, MagGeo will use sea level as your altitude (i.e. 0 Km).\n",
    "# i.e height (Only in KM)\n",
    "\n",
    "gpsfilename= \"BirdGPSTrajectoryTest.csv\"\n",
    "Lat=\"location-lat\"\n",
    "Long=\"location-long\"\n",
    "DateTime=\"timestamp\"\n",
    "altitude = \"height\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:43:39.125284Z",
     "start_time": "2021-02-16T17:43:38.434278Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here MagGeo is reading your CSV file, taking the Lat, Long, Date&Time and Altitude attributes and compute, some additional attributes we need to the annotation process.\n",
    "# Setting the date and time attributes for the required format and computing the epoch column. Values like Maximum and Minimum Date and time are also calculated.\n",
    "GPSData = getGPSData(data_dir,gpsfilename,Lat,Long,DateTime,altitude)\n",
    "GPSData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the date and time attributes for the requerided format and computing the epoch column. Values like Maximum and Minimun Date and time are also calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the right amount of Swarm measures\n",
    "\n",
    "The following loop is identifiying the time and validating if the time is less than 4:00 hours and more than 20:00 hours to bring one extra day of data. The result of this validation is written in a empty python list which will be later validated to get the unique dates avoing to download data for the same day and reducing the the downloand time process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:43:44.061064Z",
     "start_time": "2021-02-16T17:43:43.499777Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "datestimeslist = []\n",
    "for index, row in GPSData.iterrows():\n",
    "    datetimerow  = row['gpsDateTime']\n",
    "    daterow = row['dates']\n",
    "    hourrow = row['times']\n",
    "    hourrow = hourrow.strftime('%H:%M:%S')\n",
    "    if hourrow < '04:00:00':\n",
    "        date_bfr = daterow - (timedelta(days=1))\n",
    "        datestimeslist.append(daterow)\n",
    "        datestimeslist.append(date_bfr)\n",
    "    if hourrow > '20:00:00':\n",
    "        Date_aft = daterow + (timedelta(days=1))\n",
    "        datestimeslist.append(daterow)\n",
    "        datestimeslist.append(Date_aft)  \n",
    "    else:\n",
    "        datestimeslist.append(daterow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a list of unique dates, to being used to download the Swarm Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:00:45.817921Z",
     "start_time": "2021-02-15T15:00:45.347271Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def uniquelistdates(list): \n",
    "    x = np.array(list) \n",
    "    uniquelist = np.unique(x)\n",
    "    return uniquelist\n",
    "\n",
    "uniquelist_dates = uniquelistdates(datestimeslist)\n",
    "uniquelist_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Swarm residuals data\n",
    "\n",
    "Once the date and time columns have been defined, and the unique dates were identified the script can start the download process. Usually the data from Swarm is requested using only one satellite, however **MagGeo** will use the magnetic measures from the three satellite of the Swarm Mission.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "ðŸ“˜ <strong>Be aware:</strong> Due to the amount of dates the GPS track has (42 days) to request and compute the residuals, the time to process the sample data will take approximately 10 minutes.</div>\n",
    "\n",
    "Set a connection to the <code>VirES client</code> and using the function <code>Get_Swarm_residuals</code> we will get the swarm residuals for the dates included in the previous list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T15:53:19.599346Z",
     "start_time": "2021-02-15T15:00:50.100366Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "hours_t_day = 24\n",
    "hours_added = dt.timedelta(hours = hours_t_day)\n",
    "\n",
    "listdfa = []\n",
    "listdfb = []\n",
    "listdfc = []\n",
    "\n",
    "for d in tqdm(uniquelist_dates, desc=\"Getting Swarm Data\"):\n",
    "    #print(\"Getting Swarm data for date:\",d )\n",
    "    startdate = dt.datetime.combine(d, dt.datetime.min.time())\n",
    "    enddate = startdate + hours_added\n",
    "    SwarmResidualsA,SwarmResidualsB,SwarmResidualsC = Get_Swarm_residuals(startdate, enddate)\n",
    "    listdfa.append(SwarmResidualsA)\n",
    "    listdfb.append(SwarmResidualsB)\n",
    "    listdfc.append(SwarmResidualsC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat the previous results and temporally save the requested data locally:** Integrate the previous list for all dates, into pandas dataframes. We will temporally saved the previous results, in case you need to re-run MagGeo, with the following csv files you will not need to run the download process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T16:03:36.252449Z",
     "start_time": "2021-02-15T16:02:50.568350Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "TotalSwarmRes_A = pd.concat(listdfa, join='outer', axis=0)\n",
    "TotalSwarmRes_A.to_csv (os.path.join(temp_results_dir,'TotalSwarmRes_A.csv'), header=True)\n",
    "TotalSwarmRes_B = pd.concat(listdfb, join='outer', axis=0)\n",
    "TotalSwarmRes_B.to_csv (os.path.join(temp_results_dir,'TotalSwarmRes_B.csv'), header=True)\n",
    "TotalSwarmRes_C = pd.concat(listdfc, join='outer', axis=0)\n",
    "TotalSwarmRes_C.to_csv (os.path.join(temp_results_dir,'TotalSwarmRes_C.csv'), header=True)\n",
    "TotalSwarmRes_A #If you need to take a look of the Swarm Data, you can print TotalSwarmRes_B, or TotalSwarmRes_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the number of processes, and split the dataframe (GPSData) into chunks\n",
    "\n",
    "We can set the number or processess we need to dedicate for the multiprocessing mode, of course that also depends on the number of cores the machine you are using to run **MagGeo**. You can use `multiprocessing.cpu_count()` to set the number of processes as the the number of cores your machine has. Beside that we will also to split the GPS track into chucks to dedicate each core for each chuck. For more information take a look at the Home Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:43:56.199965Z",
     "start_time": "2021-02-16T17:43:51.667300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import sklearn\n",
    "from multiprocessing import Pool\n",
    "\n",
    "NumCores = multiprocessing.cpu_count()\n",
    "df_chunks = np.array_split(GPSData,NumCores)\n",
    "df_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatio-Temporal filter and Interpolation process (ST-IDW) \n",
    "\n",
    "Once we have requested the swarm data, now we need to `filter` in space and time the available points to compute the magnetic values (NEC frame) for each GPS point based on its particular date and time. The function <code>ST_IDW_Process</code> imported in the <code>row_handler</code>, takes the GPS track and the downloaded data from swarm to filter in space and time based on the criteria defined in our method. With the swarm data filtered we interpolated (IDW) the NEC components for each GPS data point, based on the latitude, date, time and number of Swarm points filtered.\n",
    "\n",
    "The function <code>CHAOS_ground_values</code>, inside the <code>MagGeoFunctions</code> file, is used to run the **Calculation of magnetic components**. This calculation requeries the magnetic components at the trajectory altitude (or at the ground level) using CHAOS (theta, phi, radial). This process include a rotation and transformation between a geocentric frame (CHAOS) and geodetic frame (GPS track). Once the corrected values are calculated, are included in the GPS track, and the non-necesary columns are removed. For more information about this process go to the Main Notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the  (ST-IDW) process in parallel mode\n",
    "\n",
    "Although the next cell seems to run a small `main` function.  What is happening is a call for several functions running at same time for several cores. Initially we set a pool of processes. Using the `pool` class we will distribute the assigned function among the data chucks we created. Every data chunk will be like a subset of the entire GPS track. So we need to iterate among data chunk. And inside every data chunk we need to identify the `datetime`, `epoch`, `altitude`, `latitude` and `longitude` of each row to run the interpolation & annotation process using the Swarm data we have filtered and stored in the previous steps.\n",
    "\n",
    "The function in charge to distribute the required function (`row_handler`) among the data chunks is the map function from the `pool` class. \n",
    "\n",
    "`row_handler.py` is an interows iteration to get the required parameter for the `ST_IDW_Process` function. \n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<strong>ðŸ“˜ Auxiliary Functions:</strong>\n",
    " \n",
    "<ol>\n",
    "  <li><strong>ST_IDW_Process</strong> function: This is the main function in charge to read the Swarm Data already filtered, and then import  <code>DfTime_func</code>,  <code>distance_to_GPS</code>, <code>Kradius</code> , <code>DistJ</code> functions to compute the spatial-time cylinder and the annotation process. The return of this function is a row (dictionary) that will be appended into a python list where all the results from the different cores. The python list from every process is concatenated into a pandas dataframe in the <code>main</code> function having there the whole chain of the parallel process.</li>\n",
    "  <li><strong>distance_to_GPS</strong> function: Is the function in charge to calculate the distance between each GPS Point and the Swarm Point.</li>\n",
    "  <li><strong>Kradius</strong> function: Is the function in charge to compute the R (radius) value in the cylinder. The R value will be considered based on the latitude of each GPS Point.</li>\n",
    "    <li><strong>DistJ</strong> function: This function will calculate the <code>d</code> value as the hypotenuse created in the triangle created amount the locations of the GPS point, the location of the Swarm points and the radius value.</li>\n",
    "  <li><strong>DfTime_func</strong> function: This is a time function to selected the points in the range of a the DeltaTime - <code>DT</code> window. The Delta time window has been set as 4 hours for each satellite trajectory.</li>\n",
    "  <li><strong>CHAOS_ground_values</strong> function: This is the calculation of geomagnetic components function to get the CHAOS magnetic values and process the Nres,Eres,Cres values and transform them into the N,E,C values at the GPS altitude.</li>\n",
    "</ol> \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:44:53.400911Z",
     "start_time": "2021-02-16T17:44:26.720610Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from functools import partial\n",
    "from utilities.row_handler import row_handler\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with multiprocessing.Pool(NumCores) as pool:\n",
    "        GeoMagParallelResult = pd.concat(pool.map(partial(row_handler),df_chunks), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Parallel mode the Annotation process takes about 12 seconds to complete ( We had tested the parallel process in a  windows server machine with 12 cores, see the image bellow). With the same GPS track in the sequetial mode the process is complete in about 2 minutes. In the image bellow you can see how the machine create several python processes and all cores (full CPU capacity) is taken.\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<strong>ðŸ”ˆ Multiprocessing:</strong>\n",
    "\n",
    "is even  more powerfull when you have to process a big amount of data (e.g. 2 millons of points). Although here is making a notable improvement if you have to process a big dataset the parallelization makes even more sense.\n",
    "\n",
    "**Be aware** that there is no output cell in here, you can follow the parallelization progress in the Anaconda Prompt.  \n",
    "\n",
    "</div>\n",
    "\n",
    "<img src=\"./images/CoresWorking.png\" style=\"zoom: 100%;\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The final result \n",
    "\n",
    "With the NEC components for each GPS Track point, it is possible to compute the aditional magnetic components. For more information about the magnetic components and their relevance go to the main paper or notebook.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <strong>ðŸ“˜ The annotated dataframe will include the following attributes:</strong> If you need more information about how the geomagnetic component are described go to the main MagGeo Notebook (Add Link).\n",
    "    <ul>\n",
    "      <li><strong>Latitude</strong> from the GPS Track.</li>\n",
    "      <li><strong>Longitude</strong> from the GPS Track.</li>\n",
    "      <li><strong>Timestamp</strong> from the GPS Track.</li>\n",
    "      <li><strong>Magnetic Field Intensity</strong>  mapped as Fgps in nanoTeslas (nT).</li>\n",
    "      <li><strong>N (Northwards) component</strong> mapped as N in nanoTeslas (nT).</li>\n",
    "      <li><strong>E (Eastwards) component</strong> mapped as E. in nanoteslas (nT).</li>\n",
    "      <li><strong>C (Downwards or Center)</strong> component mapped as C in nanoTeslas (nT).</li>\n",
    "      <li><strong>Horizontal component</strong> mapped as H in nanoTeslas (nT).</li>\n",
    "      <li><strong>Magnetic Inclination </strong> mapped as I in degrees.</li> \n",
    "      <li><strong>Magnetic Declination or dip angle</strong> mapped as D in degrees</li>\n",
    "      <li><strong>Kp Index</strong> mapped as kp</li>\n",
    "      <li><strong>Total Points</strong> as the amount of Swarm messuares included in the ST-IDW process from the trajectories requested in the three satellites.</li>\n",
    "      <li><strong>Minimum Distance</strong> mapped as MinDist, representing the minimum distance amount the set of identified point inside the Space Time cylinder and each GPS point location.</li>\n",
    "      <li><strong>Average Distance</strong> mapped as AvDist, representing the average distance amount the set of distances between the identified Swarm Point in the Space Time cylinder and the GPS Points location.</li>\n",
    "    </ul>\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:46:05.387726Z",
     "start_time": "2021-02-16T17:46:05.268724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#14. Having Intepolated and weigth magnetic values, we can compute the other magnectic components. \n",
    "GeoMagParallelResult['H'] = np.sqrt((GeoMagParallelResult['N']**2)+(GeoMagParallelResult['E']**2))\n",
    "#check the arcgtan in python., From arctan2 is saver.\n",
    "DgpsRad = np.arctan2(GeoMagParallelResult['E'],GeoMagParallelResult['N'])\n",
    "GeoMagParallelResult['D'] = np.degrees(DgpsRad)\n",
    "IgpsRad = np.arctan2(GeoMagParallelResult['C'],GeoMagParallelResult['H'])\n",
    "GeoMagParallelResult['I'] = np.degrees(IgpsRad)\n",
    "GeoMagParallelResult['F'] = np.sqrt((GeoMagParallelResult['N']**2)+(GeoMagParallelResult['E']**2)+(GeoMagParallelResult['C']**2))\n",
    "GeoMagParallelResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous dataframe (GPS_ResInt), MagGeo has computed the geomagnetic components for each locations and time of your CSV trajectory. Now we will finish up combining the original atributes from your CSV with the annotated results from MagGeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:46:05.749728Z",
     "start_time": "2021-02-16T17:46:05.393728Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "originalGPSTrack=pd.read_csv(os.path.join(data_dir,gpsfilename))\n",
    "MagGeoResult = pd.concat([originalGPSTrack, GeoMagParallelResult], axis=1)\n",
    "#Drop duplicated columns. Latitude, Longitued, and DateTime will not be part of the final result.\n",
    "MagGeoResult.drop(columns=['Latitude', 'Longitude', 'DateTime'], inplace=True)\n",
    "MagGeoResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T20:11:22.709905Z",
     "start_time": "2021-02-05T20:11:22.486852Z"
    }
   },
   "source": [
    "## Export the final results to a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:46:06.035734Z",
     "start_time": "2021-02-16T17:46:05.758730Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Exporting the CSV file\n",
    "outputfile =\"GeoMagResult_\"+gpsfilename\n",
    "export_csv = MagGeoResult.to_csv (os.path.join(results_dir,outputfile), index = None, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the results (optional)\n",
    "To validate the results we plot the `F`column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:46:31.975321Z",
     "start_time": "2021-02-16T17:46:31.734290Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Creating a copy of the results and setting the Datetime Column as dataframe index.\n",
    "ValidateDF = GeoMagParallelResult.copy()\n",
    "ValidateDF.set_index(\"DateTime\", inplace=True)\n",
    "## Plotting the F column.\n",
    "hist = ValidateDF.hist(column='F')\n",
    "plt.title('F distribution')\n",
    "plt.xlabel('F in nT')\n",
    "plt.ylabel('# of measurements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping the GPS Track using the annotated Magnetic Values (optional)\n",
    "\n",
    "Now we are going to plot the annotated GPS track stored into the MagDataFinal dataframe to see how the different magnetic components in a map to have a better prespective of the impact of the earth magnetic field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:46:09.810973Z",
     "start_time": "2021-02-16T17:46:08.014136Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ValidateDF.plot(kind=\"scatter\", x=\"Latitude\", y=\"Longitude\",\n",
    "    label=\"Magnetic Intensity in nT\",\n",
    "    c=\"F\", cmap=plt.get_cmap(\"gist_rainbow\"),\n",
    "    colorbar=True, alpha=0.4, figsize=(10,7),\n",
    "    sharex=False #This is only needed to get the x-axis label working due to a current bug in pandas plot.\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Longitude\", fontsize=12)\n",
    "plt.xlabel(\"Latitude\", fontsize=10)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:46:25.913426Z",
     "start_time": "2021-02-16T17:46:09.815973Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import geoplot\n",
    "import hvplot.pandas \n",
    "gdf = geopandas.GeoDataFrame(ValidateDF, geometry=geopandas.points_from_xy(ValidateDF.Longitude, ValidateDF.Latitude))\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdf.hvplot(title=f'Annotated trajectory using MagGeo - F GeoMag Intensity',\n",
    "           geo=True,\n",
    "           c='F',\n",
    "           tiles='CartoLight',\n",
    "           frame_width=700,\n",
    "           frame_height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.hvplot(title=f'Annotated trajectory using MagGeo - I Inclination',\n",
    "           geo=True,\n",
    "           tiles='CartoLight',\n",
    "           c='I',\n",
    "           cmap='Viridis',\n",
    "           frame_width=700,\n",
    "           frame_height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:46:28.855369Z",
     "start_time": "2021-02-16T17:46:25.919411Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "ax = world.plot(color='white', edgecolor='black', figsize = (12,6))\n",
    "\n",
    "minx, miny, maxx, maxy = gdf.total_bounds\n",
    "ax.set_xlim(minx, maxx)\n",
    "ax.set_ylim(miny, maxy)\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "gdf.plot(ax=ax, column='F', legend=True, \n",
    "         legend_kwds={'label': \"Magnetic Intensity in nT\",\n",
    "                      'orientation': \"horizontal\"})\n",
    "plt.ylabel(\"Longitude\", fontsize=9)\n",
    "plt.xlabel(\"Latitude\", fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T17:46:31.732297Z",
     "start_time": "2021-02-16T17:46:28.857955Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (15,6))\n",
    "\n",
    "ax1 = world.plot(ax=ax1, color='white', edgecolor='black')\n",
    "xlim = ([gdf.total_bounds[0],  gdf.total_bounds[2]])\n",
    "ylim = ([gdf.total_bounds[1],  gdf.total_bounds[3]])\n",
    "ax1.set_xlim(xlim)\n",
    "ax1.set_ylim(ylim)\n",
    "\n",
    "\n",
    "gdf.plot(ax=ax1, column='F', legend=True,\n",
    "         legend_kwds={'label': \"Magnetic Intensity in nT\",\n",
    "                      'orientation': \"horizontal\"})\n",
    "plt.ylabel(\"Longitude\", fontsize=9)\n",
    "plt.xlabel(\"Latitude\", fontsize=9)\n",
    "ax1.set_title('Magnetic Intensity - F')\n",
    "ax1.set_xlabel('Latitude')\n",
    "ax1.set_ylabel('Longitude')\n",
    "\n",
    "\n",
    "ax2 = world.plot( ax=ax2, color='white', edgecolor='black')\n",
    "xlim = ([gdf.total_bounds[0],  gdf.total_bounds[2]])\n",
    "ylim = ([gdf.total_bounds[1],  gdf.total_bounds[3]])\n",
    "ax2.set_xlim(xlim)\n",
    "ax2.set_ylim(ylim)\n",
    "\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "gdf.plot(ax=ax2, column='D', legend=True, cmap='Spectral', \n",
    "         legend_kwds={'label': \" Declination in Degrees\",\n",
    "                      'orientation': \"horizontal\"})\n",
    "ax2.set_title('Declination - D')\n",
    "ax2.set_xlabel('Latitude')\n",
    "ax2.set_ylabel('Longitude')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
